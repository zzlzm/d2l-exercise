{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af98a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bfe6f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "外积： tensor([ 8, 18])\n",
      "内积（点积）： tensor(11)\n",
      "哈德玛积： tensor([3, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([2, 3])\n",
    "print('外积：', torch.matmul(a, b))\n",
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])\n",
    "print('内积（点积）：', torch.dot(x, y))\n",
    "print('哈德玛积：', x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "848a38eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x.requires_grad_(True)\n",
    "y = 2 * torch.dot(x, x)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba01e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16cd0885",
   "metadata": {},
   "source": [
    "## 线性回归\n",
    "1. 构造数据\n",
    "2. 定义取数函数（小批量梯度下降需要随机取数）\n",
    "2. 定义损失函数\n",
    "3. 定义优化函数\n",
    "4. 定义预测模型 $y=WX+b$\n",
    "5. 进行多轮训练\n",
    "6. 训练效果检测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589fbe3",
   "metadata": {},
   "source": [
    "### 构造数据\n",
    "构造一个线性数据集，假设有两个变量\n",
    "$y = w1 * x1 + w2 * x2 + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb53629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5342, -1.2330]) tensor([-10.7807])\n"
     ]
    }
   ],
   "source": [
    "W = torch.tensor([5., 10])\n",
    "b = 4.2\n",
    "X = torch.normal(0, 1, (1000, 2))\n",
    "noise = torch.normal(1, 0.1, (1, 1))\n",
    "y = torch.matmul(X, W.reshape(2, 1)) + b\n",
    "y +=  torch.normal(0, 0.01, y.shape)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4d992ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f3b5df494f0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图验证下y和x1之间是线性关系\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "ax.scatter(X[:, 0], y, s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15488bea",
   "metadata": {},
   "source": [
    "### 定义损失函数\n",
    "平方损失 $loss = \\frac{1}{2} * (y - yhat) ^ 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0559e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_hat, y):\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c16b4",
   "metadata": {},
   "source": [
    "### 定义优化函数\n",
    "梯度下降法向参数的真实值逼近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aec8756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b0e1b",
   "metadata": {},
   "source": [
    "### 定义取数函数\n",
    "小批量梯度下降法需要从数据集里随机取小批量的数据来进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "158ef96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, res, batch_size):\n",
    "    idx = list(range(len(data)))\n",
    "    np.random.shuffle(idx)\n",
    "    for i in range(0, len(idx), batch_size):\n",
    "        indices = idx[i:i + batch_size]\n",
    "        yield data[indices], res[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7918176",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b88386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(X, W, b):\n",
    "    return torch.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd74b3",
   "metadata": {},
   "source": [
    "### 定义训练训练函数\n",
    "求y_hat，然后调用损失函数，对参数求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "abea0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意下两个train函数，本质的区别是 第一个只取3次值\n",
    "# 第二个train 所有的值取一遍，循环三遍\n",
    "def train(data, res, W, b, lr, epochs, batch_size):\n",
    "    train_iter = get_data(data, res, batch_size)\n",
    "    for i in range(epochs):\n",
    "        train_data, res_data = next(train_iter)\n",
    "        l = loss(linear_reg(train_data, W, b), res_data)\n",
    "        l.sum().backward()\n",
    "        sgd([W, b], lr, batch_size)\n",
    "        with torch.no_grad():\n",
    "            train_l = loss(linear_reg(train_data, W, b), res_data)\n",
    "            print('epoch', i + 1, 'loss:', train_l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e63cbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, res, W, b, lr, epochs, batch_size):\n",
    "    for i in range(epochs):\n",
    "        for train_data, res_data in get_data(data, res, batch_size):\n",
    "            l = loss(linear_reg(train_data, W, b), res_data)\n",
    "            l.sum().backward()\n",
    "            sgd([W, b], lr, batch_size)\n",
    "            print('w is', W.detach().numpy().reshape(1, -1))\n",
    "        with torch.no_grad():\n",
    "            train_l = loss(linear_reg(train_data, W, b), res_data)\n",
    "            print(f'epoch, {i + 1}, loss:, {float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c869a",
   "metadata": {},
   "source": [
    "### 初始化变量开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48ab471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w is [[0.9427955 1.0027084]]\n",
      "w is [[1.0612068 1.1014646]]\n",
      "w is [[1.1079193 1.2406998]]\n",
      "w is [[1.0963954 1.5252073]]\n",
      "w is [[1.1171644 1.6285212]]\n",
      "w is [[1.160728  1.6503353]]\n",
      "w is [[1.3075079 1.8066338]]\n",
      "w is [[1.443762  2.1214213]]\n",
      "w is [[1.5571579 2.260409 ]]\n",
      "w is [[1.8272438 2.4394863]]\n",
      "w is [[1.8175098 2.495621 ]]\n",
      "w is [[1.9774592 2.7748513]]\n",
      "w is [[2.1116045 2.957442 ]]\n",
      "w is [[2.1827273 3.1113832]]\n",
      "w is [[2.2763107 3.316935 ]]\n",
      "w is [[2.451178 3.593502]]\n",
      "w is [[2.5694828 3.7337308]]\n",
      "w is [[2.6806648 3.958171 ]]\n",
      "w is [[2.9516778 4.403363 ]]\n",
      "w is [[3.0214674 4.5340433]]\n",
      "w is [[3.194646 4.626357]]\n",
      "w is [[3.2443516 4.7478037]]\n",
      "w is [[3.2902436 4.8737364]]\n",
      "w is [[3.2345414 4.941155 ]]\n",
      "w is [[3.2784216 5.081754 ]]\n",
      "w is [[3.3851333 5.199899 ]]\n",
      "w is [[3.4471989 5.3479414]]\n",
      "w is [[3.4702678 5.5299373]]\n",
      "w is [[3.5628347 5.6553483]]\n",
      "w is [[3.5729406 5.7634206]]\n",
      "w is [[3.546218  5.8385954]]\n",
      "w is [[3.4740567 6.0147185]]\n",
      "w is [[3.5120723 6.2340794]]\n",
      "w is [[3.510368  6.3209314]]\n",
      "w is [[3.4911098 6.4503345]]\n",
      "w is [[3.5472808 6.615069 ]]\n",
      "w is [[3.556385 6.692044]]\n",
      "w is [[3.571632 6.723035]]\n",
      "w is [[3.638768  6.7886043]]\n",
      "w is [[3.708144 6.860633]]\n",
      "w is [[3.7374828 6.9310884]]\n",
      "w is [[3.7512107 6.96701  ]]\n",
      "w is [[3.837681 7.031419]]\n",
      "w is [[3.861121 7.108525]]\n",
      "w is [[3.9024227 7.2031937]]\n",
      "w is [[3.944342  7.3074546]]\n",
      "w is [[3.9415119 7.371592 ]]\n",
      "w is [[3.9531837 7.4471602]]\n",
      "w is [[3.969752  7.4644876]]\n",
      "w is [[4.0410414 7.52732  ]]\n",
      "w is [[4.085241 7.605797]]\n",
      "w is [[4.156835  7.6364837]]\n",
      "w is [[4.1756473 7.7268987]]\n",
      "w is [[4.1952925 7.7941675]]\n",
      "w is [[4.2145395 7.836361 ]]\n",
      "w is [[4.2709246 7.933751 ]]\n",
      "w is [[4.3240914 7.9860015]]\n",
      "w is [[4.361977 8.053694]]\n",
      "w is [[4.381891 8.161043]]\n",
      "w is [[4.423382 8.266046]]\n",
      "w is [[4.433995 8.314844]]\n",
      "w is [[4.434157 8.358065]]\n",
      "w is [[4.4386644 8.413319 ]]\n",
      "w is [[4.4506073 8.501075 ]]\n",
      "w is [[4.466554 8.566603]]\n",
      "w is [[4.491679 8.589418]]\n",
      "w is [[4.537153 8.629708]]\n",
      "w is [[4.5452223 8.669536 ]]\n",
      "w is [[4.542405 8.696112]]\n",
      "w is [[4.5476174 8.7237425]]\n",
      "w is [[4.5474257 8.748993 ]]\n",
      "w is [[4.569132 8.77069 ]]\n",
      "w is [[4.5934253 8.822977 ]]\n",
      "w is [[4.6151333 8.864595 ]]\n",
      "w is [[4.6184025 8.873744 ]]\n",
      "w is [[4.6266384 8.948932 ]]\n",
      "w is [[4.6320853 8.972175 ]]\n",
      "w is [[4.639296 9.025529]]\n",
      "w is [[4.661808 9.051326]]\n",
      "w is [[4.6712604 9.07351  ]]\n",
      "w is [[4.6728954 9.092672 ]]\n",
      "w is [[4.6918397 9.127872 ]]\n",
      "w is [[4.69011  9.164933]]\n",
      "w is [[4.691279 9.181437]]\n",
      "w is [[4.699748 9.193457]]\n",
      "w is [[4.702109 9.235447]]\n",
      "w is [[4.7158484 9.258339 ]]\n",
      "w is [[4.710341 9.283697]]\n",
      "w is [[4.7193418 9.305766 ]]\n",
      "w is [[4.733647 9.353194]]\n",
      "w is [[4.7435594 9.374677 ]]\n",
      "w is [[4.7487855 9.402548 ]]\n",
      "w is [[4.7631097 9.415605 ]]\n",
      "w is [[4.763254 9.420069]]\n",
      "w is [[4.7788076 9.444013 ]]\n",
      "w is [[4.784467 9.446439]]\n",
      "w is [[4.7813163 9.4644165]]\n",
      "w is [[4.798683 9.480816]]\n",
      "w is [[4.8035192 9.4903   ]]\n",
      "w is [[4.809907 9.517172]]\n",
      "epoch, 1, loss:, 0.235117\n",
      "w is [[4.820602 9.524558]]\n",
      "w is [[4.812958 9.54796 ]]\n",
      "w is [[4.8170466 9.561041 ]]\n",
      "w is [[4.8154054 9.564978 ]]\n",
      "w is [[4.8301573 9.580826 ]]\n",
      "w is [[4.833288 9.596854]]\n",
      "w is [[4.8382597 9.613553 ]]\n",
      "w is [[4.843748 9.619418]]\n",
      "w is [[4.8457456 9.630438 ]]\n",
      "w is [[4.849069 9.647303]]\n",
      "w is [[4.8521767 9.649384 ]]\n",
      "w is [[4.85397 9.66111]]\n",
      "w is [[4.8589725 9.670811 ]]\n",
      "w is [[4.8661275 9.675148 ]]\n",
      "w is [[4.881102 9.692569]]\n",
      "w is [[4.8846393 9.703088 ]]\n",
      "w is [[4.893117 9.712709]]\n",
      "w is [[4.9021034 9.721725 ]]\n",
      "w is [[4.9056296 9.729257 ]]\n",
      "w is [[4.9069943 9.74528  ]]\n",
      "w is [[4.9101334 9.754337 ]]\n",
      "w is [[4.9114017 9.761712 ]]\n",
      "w is [[4.914344 9.767103]]\n",
      "w is [[4.912116 9.772089]]\n",
      "w is [[4.912302 9.774009]]\n",
      "w is [[4.9120765 9.777121 ]]\n",
      "w is [[4.914211 9.782702]]\n",
      "w is [[4.913956 9.786208]]\n",
      "w is [[4.9219036 9.796107 ]]\n",
      "w is [[4.9275947 9.801831 ]]\n",
      "w is [[4.9290853 9.805657 ]]\n",
      "w is [[4.932786 9.81093 ]]\n",
      "w is [[4.939324 9.820372]]\n",
      "w is [[4.943304  9.8263445]]\n",
      "w is [[4.944423 9.829361]]\n",
      "w is [[4.9474134 9.835114 ]]\n",
      "w is [[4.9489183 9.838265 ]]\n",
      "w is [[4.947748 9.842404]]\n",
      "w is [[4.9501376 9.84596  ]]\n",
      "w is [[4.9542284 9.855044 ]]\n",
      "w is [[4.9550757 9.858372 ]]\n",
      "w is [[4.955536 9.863011]]\n",
      "w is [[4.9601736 9.8684   ]]\n",
      "w is [[4.9596667 9.87037  ]]\n",
      "w is [[4.959545 9.874641]]\n",
      "w is [[4.960255 9.881235]]\n",
      "w is [[4.9603667 9.883778 ]]\n",
      "w is [[4.9641743 9.888473 ]]\n",
      "w is [[4.9647446 9.890748 ]]\n",
      "w is [[4.964154 9.893693]]\n",
      "w is [[4.96661  9.900345]]\n",
      "w is [[4.968514 9.902328]]\n",
      "w is [[4.9692993 9.904277 ]]\n",
      "w is [[4.969524 9.907097]]\n",
      "w is [[4.970613 9.913669]]\n",
      "w is [[4.971031 9.915548]]\n",
      "w is [[4.9720845 9.916571 ]]\n",
      "w is [[4.9723296 9.91967  ]]\n",
      "w is [[4.972493 9.920269]]\n",
      "w is [[4.9743843 9.926688 ]]\n",
      "w is [[4.974489 9.92947 ]]\n",
      "w is [[4.9745946 9.930663 ]]\n",
      "w is [[4.975384 9.931535]]\n",
      "w is [[4.974773 9.933718]]\n",
      "w is [[4.97537  9.934536]]\n",
      "w is [[4.975134 9.935803]]\n",
      "w is [[4.975685 9.93785 ]]\n",
      "w is [[4.977192  9.9408455]]\n",
      "w is [[4.9782515 9.941702 ]]\n",
      "w is [[4.978693 9.943483]]\n",
      "w is [[4.980315 9.944543]]\n",
      "w is [[4.980839 9.946323]]\n",
      "w is [[4.98105  9.948648]]\n",
      "w is [[4.982049 9.949998]]\n",
      "w is [[4.982365 9.950222]]\n",
      "w is [[4.9831185 9.95127  ]]\n",
      "w is [[4.9833875 9.953417 ]]\n",
      "w is [[4.9837375 9.953796 ]]\n",
      "w is [[4.9842443 9.954552 ]]\n",
      "w is [[4.9837437 9.956084 ]]\n",
      "w is [[4.9838147 9.956598 ]]\n",
      "w is [[4.9842443 9.957775 ]]\n",
      "w is [[4.984556 9.958948]]\n",
      "w is [[4.984718 9.95976 ]]\n",
      "w is [[4.9851947 9.960234 ]]\n",
      "w is [[4.9850187 9.961059 ]]\n",
      "w is [[4.985191 9.96135 ]]\n",
      "w is [[4.985848 9.962552]]\n",
      "w is [[4.986155 9.962973]]\n",
      "w is [[4.98741  9.964692]]\n",
      "w is [[4.987286  9.9661255]]\n",
      "w is [[4.98706 9.96672]]\n",
      "w is [[4.987649  9.9678335]]\n",
      "w is [[4.988313 9.969062]]\n",
      "w is [[4.988723 9.970169]]\n",
      "w is [[4.988774 9.970615]]\n",
      "w is [[4.989758 9.972453]]\n",
      "w is [[4.990159 9.97391 ]]\n",
      "w is [[4.9910107 9.974509 ]]\n",
      "w is [[4.991308 9.974998]]\n",
      "epoch, 2, loss:, 0.000409\n",
      "w is [[4.991167 9.97557 ]]\n",
      "w is [[4.991898 9.975952]]\n",
      "w is [[4.991769 9.97703 ]]\n",
      "w is [[4.991727 9.977581]]\n",
      "w is [[4.992193 9.978038]]\n",
      "w is [[4.9927144 9.978535 ]]\n",
      "w is [[4.993164 9.979147]]\n",
      "w is [[4.993292  9.9804535]]\n",
      "w is [[4.9936543 9.981018 ]]\n",
      "w is [[4.9941883 9.982013 ]]\n",
      "w is [[4.9943647 9.982918 ]]\n",
      "w is [[4.99437  9.983885]]\n",
      "w is [[4.9947824 9.984422 ]]\n",
      "w is [[4.9948387 9.984557 ]]\n",
      "w is [[4.995083 9.98545 ]]\n",
      "w is [[4.994832 9.985792]]\n",
      "w is [[4.9948835 9.98612  ]]\n",
      "w is [[4.9950123 9.986405 ]]\n",
      "w is [[4.995009 9.986754]]\n",
      "w is [[4.9953957 9.987028 ]]\n",
      "w is [[4.995627 9.98759 ]]\n",
      "w is [[4.9957185 9.988133 ]]\n",
      "w is [[4.9958134 9.988327 ]]\n",
      "w is [[4.995911 9.988608]]\n",
      "w is [[4.9959474 9.988945 ]]\n",
      "w is [[4.996091 9.989146]]\n",
      "w is [[4.9962544 9.989442 ]]\n",
      "w is [[4.9964814 9.98986  ]]\n",
      "w is [[4.9968686 9.990359 ]]\n",
      "w is [[4.9970603 9.990839 ]]\n",
      "w is [[4.9973283 9.991032 ]]\n",
      "w is [[4.99756  9.991377]]\n",
      "w is [[4.997476 9.991877]]\n",
      "w is [[4.9972925 9.9922495]]\n",
      "w is [[4.997451 9.992423]]\n",
      "w is [[4.9977474 9.99287  ]]\n",
      "w is [[4.997756  9.9930105]]\n",
      "w is [[4.9978085 9.993571 ]]\n",
      "w is [[4.9978075 9.993783 ]]\n",
      "w is [[4.9977407 9.993875 ]]\n",
      "w is [[4.9976106 9.993917 ]]\n",
      "w is [[4.997636 9.994058]]\n",
      "w is [[4.9976425 9.994166 ]]\n",
      "w is [[4.9977903 9.994194 ]]\n",
      "w is [[4.9979024 9.994344 ]]\n",
      "w is [[4.9980288 9.994507 ]]\n",
      "w is [[4.998009 9.994603]]\n",
      "w is [[4.998168 9.99465 ]]\n",
      "w is [[4.998324 9.994679]]\n",
      "w is [[4.9983892 9.9948015]]\n",
      "w is [[4.998378 9.995047]]\n",
      "w is [[4.9984007 9.995157 ]]\n",
      "w is [[4.9983687 9.995274 ]]\n",
      "w is [[4.9985976 9.995417 ]]\n",
      "w is [[4.9985166 9.995583 ]]\n",
      "w is [[4.9984617 9.995692 ]]\n",
      "w is [[4.998505 9.995716]]\n",
      "w is [[4.998511 9.995677]]\n",
      "w is [[4.9984274 9.995834 ]]\n",
      "w is [[4.9982905 9.995998 ]]\n",
      "w is [[4.9984927 9.996126 ]]\n",
      "w is [[4.9986057 9.996319 ]]\n",
      "w is [[4.998612 9.99637 ]]\n",
      "w is [[4.9988008 9.996523 ]]\n",
      "w is [[4.9989853 9.996527 ]]\n",
      "w is [[4.9990754 9.996495 ]]\n",
      "w is [[4.9989996 9.996514 ]]\n",
      "w is [[4.999037 9.996713]]\n",
      "w is [[4.9990625 9.996842 ]]\n",
      "w is [[4.9989552 9.997113 ]]\n",
      "w is [[4.9988174 9.997462 ]]\n",
      "w is [[4.998796 9.997451]]\n",
      "w is [[4.9987936 9.997477 ]]\n",
      "w is [[4.998849 9.997537]]\n",
      "w is [[4.999066 9.99747 ]]\n",
      "w is [[4.999006 9.997535]]\n",
      "w is [[4.9990673 9.99756  ]]\n",
      "w is [[4.9990277 9.997559 ]]\n",
      "w is [[4.999068 9.997758]]\n",
      "w is [[4.9992175 9.997755 ]]\n",
      "w is [[4.9991803 9.997793 ]]\n",
      "w is [[4.999267 9.997781]]\n",
      "w is [[4.9993815 9.997945 ]]\n",
      "w is [[4.99942  9.998014]]\n",
      "w is [[4.999488 9.998014]]\n",
      "w is [[4.9995556 9.997875 ]]\n",
      "w is [[4.999742  9.9979315]]\n",
      "w is [[4.9998   9.997819]]\n",
      "w is [[4.999898 9.997933]]\n",
      "w is [[5.000071 9.998069]]\n",
      "w is [[5.0000725 9.998143 ]]\n",
      "w is [[4.9999275 9.998245 ]]\n",
      "w is [[4.9998174 9.9983225]]\n",
      "w is [[4.9997563 9.998448 ]]\n",
      "w is [[4.9997406 9.998624 ]]\n",
      "w is [[4.9998055 9.998541 ]]\n",
      "w is [[4.9999375 9.99851  ]]\n",
      "w is [[4.999887 9.998481]]\n",
      "w is [[5.0000253 9.998756 ]]\n",
      "w is [[5.000005 9.998845]]\n",
      "epoch, 3, loss:, 0.000041\n",
      "[[5.000005]\n",
      " [9.998845]] [4.199369]\n"
     ]
    }
   ],
   "source": [
    "train_W = torch.normal(1, 0.1, (2, 1), requires_grad=True)\n",
    "train_b = torch.zeros(1, requires_grad=True)\n",
    "lr = 0.03\n",
    "epochs = 3\n",
    "batch_size = 10\n",
    "train(X, y, train_W, train_b, lr, epochs, batch_size)\n",
    "\n",
    "print(train_W.detach().numpy(), train_b.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6516f48",
   "metadata": {},
   "source": [
    "### 和真实结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c6292ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(6.1466e-06)\n"
     ]
    }
   ],
   "source": [
    "test_iter = get_data(X, y, batch_size)\n",
    "test_data, test_res = next(test_iter)\n",
    "with torch.no_grad():\n",
    "    y_hat = linear_reg(test_data, train_W, train_b)\n",
    "    l = loss(test_res, y_hat) / batch_size\n",
    "    print('loss: ', l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c7523a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[0], [0], [1]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6197d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [3]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.tensor([[2], [4], [3]])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6b817df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900],\n",
       "        [0.6652],\n",
       "        [0.2447]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(data):\n",
    "    return torch.exp(data) / torch.exp(data).sum()\n",
    "softmax(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a183ca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([1, 2]) ** 2 / 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5e6e5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([[1, 2], [1, 2]]) ** 2 / 2).sum() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858e2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
